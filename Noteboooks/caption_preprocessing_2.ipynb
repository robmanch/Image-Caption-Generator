{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cad2609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re # To clean the tweets\n",
    "import string\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22319a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f9c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"D:\\GBC2\\DL1\\Project\\Data\\flickr_8k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e169d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file, file_name):\n",
    "    pickle.dump(file, open(file_name + \".pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348f66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_caption(path):\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        text = file.read()\n",
    "    text = text.split('\\n')[1:-1]\n",
    "    print(f\"Total number of captions: {len(text)}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd3e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of captions: 40455\n"
     ]
    }
   ],
   "source": [
    "data = read_caption(DATA_PATH + r'\\captions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb7584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_caption_dic(text):\n",
    "    \n",
    "    captions = dict()\n",
    "    for line in text:\n",
    "        image_name  = line.split(',')[0]\n",
    "        caption  = line.split(',')[1:]\n",
    "        caption = \" \".join(caption)\n",
    "        image_name = image_name.split('.')[0]\n",
    "        if image_name not in captions.keys():\n",
    "            captions[image_name] = []\n",
    "        captions[image_name].append(caption) \n",
    "    print(f\"Total number of images: {len(captions)}\")\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c746df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 8091\n"
     ]
    }
   ],
   "source": [
    "captions_dic = img_caption_dic(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335dd5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(captions_dic, \"captions_dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6b5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(s):\n",
    "    \"\"\"This function cleans the text\n",
    "    Input: string to be cleaned\n",
    "    Return: string after cleaning\n",
    "    \"\"\"\n",
    "    words = [] # empty list\n",
    "    \n",
    "    s = s.strip().lower() # lower the string\n",
    "    s = re.sub('\\[.*?\\]', '', s) # removes symbols (.*?\\)\n",
    "    s = re.sub('https?://\\S+|www\\.\\S+', '', s) # remove URLS\n",
    "    s = re.sub('<.*?>+', '', s)\n",
    "    s = re.sub('[%s]' % re.escape(string.punctuation), '', s) # remove punctuations\n",
    "    s = re.sub('\\n', '', s) # remove next line character\n",
    "    s = re.sub('\\w*\\d\\w*', '', s) # remove alpha numeric words\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dfaaf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_captions(captions):\n",
    "    \n",
    "    for image_name, caption_list in captions.items():\n",
    "        for i in range(len(caption_list)):\n",
    "            clean_caption = text_clean(captions[image_name][i])\n",
    "            captions[image_name][i] = clean_caption\n",
    "        \n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7a2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_captions_dic = clean_captions(captions_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3a5471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_captions_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5552f87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40455\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for v in clean_captions_dic.values():\n",
    "    count += len(v)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fddb7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(captions):\n",
    "    vocab = []\n",
    "    for caption_list in captions.values():\n",
    "        vocab.append(caption_list)\n",
    "        \n",
    "    vocab = set(\" \".join(np.array(vocab).ravel()).split())\n",
    "    print(f\"Total number of words in vocabulary: {len(vocab)}\")\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af1cd095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in vocabulary: 8775\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(clean_captions_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65bc94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(clean_captions_dic, \"clean_captions_dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b049d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(vocab, \"vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d36a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 8091 \n",
      "Number of images in training dataset: 6473 \n",
      "Number of images in validation dataset: 1618\n"
     ]
    }
   ],
   "source": [
    "all_image_name = list(clean_captions_dic.keys())\n",
    "total_images = len(all_image_name)\n",
    "val_percent = 0.2\n",
    "np.random.seed(42)\n",
    "val_image_name = np.random.choice(all_image_name, size = int(total_images*val_percent), replace = False)\n",
    "train_image_name = [name for name in all_image_name if name not in val_image_name]\n",
    "print(f\"Total number of images: {total_images}\",f\"\\nNumber of images in training dataset: {len(train_image_name)}\", f\"\\nNumber of images in validation dataset: {len(val_image_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1222c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_captions(names):\n",
    "    \n",
    "    cap_dict = dict()\n",
    "    for name in names:\n",
    "        if name not in cap_dict.keys():\n",
    "            cap_dict[name] = []\n",
    "        caption_list = clean_captions_dic[name]\n",
    "        for caption in caption_list:\n",
    "            caption = \"sos \" + caption + \" eos\"\n",
    "            cap_dict[name].append(caption)\n",
    "            \n",
    "    return cap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bfa4f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6473 1618\n"
     ]
    }
   ],
   "source": [
    "train_captions = train_val_captions(train_image_name)\n",
    "val_captions = train_val_captions(val_image_name)\n",
    "print(len(train_image_name), len(val_image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "165c4726",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(train_captions, 'train_captions')\n",
    "save_pickle(val_captions, 'val_captions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac21b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encodings = pickle.load(open(\"img_enc_dic.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd23f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_encodings(names):\n",
    "    \n",
    "    enc_dic = dict()\n",
    "    for name in names:\n",
    "        enc_dic[name] = image_encodings[name]\n",
    "        \n",
    "    return enc_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "002d0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6473 1618\n"
     ]
    }
   ],
   "source": [
    "train_img_encodings = train_val_encodings(train_image_name)\n",
    "val_img_encodings = train_val_encodings(val_image_name)\n",
    "print(len(train_img_encodings), len(val_img_encodings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "117ef8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(train_img_encodings, 'train_img_encodings')\n",
    "save_pickle(val_img_encodings, 'val_img_encodings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4fa31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tokenizer(cap_dic):\n",
    "    \n",
    "    text = np.array(list(cap_dic.values())).ravel().tolist()\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e03951b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = build_tokenizer(train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c81c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(tokenizer, 'tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61b601ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_word_dic ={value: key for key, value in tokenizer.word_index.items()}\n",
    "save_pickle(idx_word_dic, 'idx_word_dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baba7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d730eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(cap_dic, tokenizer, max_length, vocab_size, encodings):\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for name, caption_list in cap_dic.items():\n",
    "#         print(name, caption_list)\n",
    "        for caption in caption_list:\n",
    "            sequences = tokenizer.texts_to_sequences([caption])[0]\n",
    "            for i in range(1, len(sequences)):\n",
    "                in_seq, out_seq = sequences[:i], sequences[i]\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "#                 print(in_seq, out_seq, encodings[name][0])\n",
    "                x1.append(encodings[name][0])\n",
    "                x2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "    \n",
    "    return np.array(x1), np.array(x2), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae6d8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_length(cap_dic):\n",
    "    len_list = []\n",
    "    for caption_list in cap_dic.values():\n",
    "        for caption in caption_list:\n",
    "            len_list.append(len(caption.split()))\n",
    "            \n",
    "    return max(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e038e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = find_max_length(train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c658696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(max_length, \"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cc2dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x2_train, y_train = create_sequences(train_captions, tokenizer, max_length, vocab_size, train_img_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b44d7f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381626, 4096) (381626, 37) (381626, 7984)\n"
     ]
    }
   ],
   "source": [
    "print(x1_train.shape, x2_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ff5f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(x1_train, 'x1_train')\n",
    "save_pickle(x2_train, 'x2_train')\n",
    "save_pickle(y_train, 'y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87c14183",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_val, x2_val, y_val = create_sequences(val_captions, tokenizer, max_length, vocab_size, val_img_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60677de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94181, 4096) (94181, 37) (94181, 7984)\n"
     ]
    }
   ],
   "source": [
    "print(x1_val.shape, x2_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54655a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(x1_val, 'x1_val')\n",
    "save_pickle(x2_val, 'x2_val')\n",
    "save_pickle(y_val, 'y_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c76fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_caption",
   "language": "python",
   "name": "image_caption"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
